# OOD Detection & Neural Collapse

**Practical Work â€” Theory of Deep Learning (MVA + ENSTA)**  
Author: Aziz BEN AMIRA â€” February 2026

---

## ğŸš€ New to This Project? Start Here

**Complete setup guide for GPU clusters:** see [SETUP.md](SETUP.md)

**Quick start:**
```bash
# 1. Clone and setup
git clone https://github.com/your-username/ood_detection.git
cd ood_detection/project
pip install -r requirements.txt

# 2. Run full pipeline (200 epochs, ~3h on GPU)
python main.py --epochs 200

# 3. Check results
cat outputs/results/summary.json
```

---

## Overview

This project implements:

1. **ResNet-18 training** on CIFAR-100 (200 epochs, cosine annealing LR)
2. **6 OOD detection methods**: MSP, Max Logit, Energy, Mahalanobis, ViM, NECO
3. **Neural Collapse analysis** (NC1â€“NC5): within-class collapse, Simplex ETF, self-duality, NCC
4. **Bonus**: Neural Collapse across layers
5. Full visualizations, AUROC metrics, and result export

**Datasets**: CIFAR-100 (in-distribution), SVHN and DTD (out-of-distribution)

---

## Project Structure

```
project/
â”œâ”€â”€ README.md                   â† you are here
â”œâ”€â”€ requirements.txt            â† pip dependencies
â”œâ”€â”€ config.py                   â† all hyperparameters & paths
â”œâ”€â”€ main.py                     â† full pipeline (train + eval + analysis)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ resnet_cifar.py     â† ResNet-18 adapted for CIFAR (32Ã—32)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ datasets.py         â† CIFAR-100, SVHN, DTD loaders
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trainer.py          â† training loop + checkpointing + resume
â”‚   â”œâ”€â”€ ood/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scores.py           â† MSP, MaxLogit, Energy, Mahalanobis, ViM, NECO
â”‚   â”‚   â””â”€â”€ evaluation.py       â† AUROC computation + batch evaluation
â”‚   â”œâ”€â”€ neural_collapse/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py          â† NC1-NC4 measurement functions
â”‚   â”‚   â””â”€â”€ analysis.py         â† NC1-NC5 orchestration + across-layers bonus
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ feature_extraction.py  â† penultimate layer + multi-layer hooks
â”‚       â””â”€â”€ visualization.py       â† all plots saved as PNG (headless-safe)
â””â”€â”€ scripts/
    â”œâ”€â”€ train.py                â† standalone training script
    â”œâ”€â”€ evaluate_ood.py         â† standalone OOD evaluation
    â””â”€â”€ analyze_nc.py           â† standalone Neural Collapse analysis
```

---

## Quick Start

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the full pipeline (recommended)

```bash
python main.py --epochs 200 --data-dir ./data --output-dir ./outputs
```

This will:
- Train ResNet-18 on CIFAR-100 for 200 epochs
- Evaluate all 6 OOD detection methods on SVHN (and DTD if available)
- Run the full Neural Collapse analysis (NC1â€“NC5 + across layers)
- Save all plots, logs, checkpoints, and JSON results under `./outputs/`

### 3. Or run each step separately

```bash
# Step 1: Train
python scripts/train.py --epochs 200 --data-dir ./data --output-dir ./outputs

# Step 2: Evaluate OOD (requires trained model)
python scripts/evaluate_ood.py \
    --checkpoint outputs/checkpoints/best_model.pth \
    --data-dir ./data --output-dir ./outputs

# Step 3: Neural Collapse analysis (requires trained model)
python scripts/analyze_nc.py \
    --checkpoint outputs/checkpoints/best_model.pth \
    --data-dir ./data --output-dir ./outputs
```

### 4. Resume training from a checkpoint

```bash
python scripts/train.py --resume outputs/checkpoints/checkpoint_epoch100.pth
```

### 5. Skip training and reuse an existing checkpoint

```bash
python main.py --skip-train --checkpoint outputs/checkpoints/best_model.pth
```

---

## GPU Cluster Usage (SLURM / sbatch)

Create a file `job.sh`:

```bash
#!/bin/bash
#SBATCH --job-name=ood_nc
#SBATCH --output=slurm_%j.out
#SBATCH --error=slurm_%j.err
#SBATCH --time=04:00:00
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --partition=gpu

# Load modules (adapt to your cluster)
module load python/3.10
module load cuda/11.8

# Activate virtualenv
source ~/venvs/ood/bin/activate

# Run the full pipeline
cd /path/to/project
python main.py \
    --epochs 200 \
    --data-dir ./data \
    --output-dir ./outputs \
    --num-workers 4 \
    --batch-size 128
```

Submit with:

```bash
sbatch job.sh
```

Monitor progress:

```bash
# Live logs
tail -f outputs/logs/main.log

# Check SLURM output
tail -f slurm_*.out
```

---

## Outputs

After a full run, `outputs/` will contain:

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth              â† best model weights (by test accuracy)
â”‚   â”œâ”€â”€ checkpoint_epoch010.pth     â† full checkpoint (model + optimizer + scheduler)
â”‚   â”œâ”€â”€ checkpoint_epoch020.pth
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ main.log                    â† or train.log / evaluate_ood.log / analyze_nc.log
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ training_curves.png         â† loss, accuracy, LR schedule
â”‚   â”œâ”€â”€ ood_scores_svhn.png         â† score distributions for each method
â”‚   â”œâ”€â”€ final_ood_comparison_svhn.png  â† AUROC bar chart
â”‚   â”œâ”€â”€ neco_analysis_svhn.png      â† NECO score + similarity patterns
â”‚   â”œâ”€â”€ neural_collapse_nc1_nc4.png â† 6-panel NC analysis
â”‚   â””â”€â”€ nc_across_layers.png        â† NC1 vs layer depth (bonus)
â””â”€â”€ results/
    â”œâ”€â”€ training_history.json       â† per-epoch metrics
    â”œâ”€â”€ ood_results.json            â† AUROC for each method Ã— dataset
    â”œâ”€â”€ nc_results.json             â† all NC metrics
    â””â”€â”€ summary.json                â† combined summary
```

---

## Command-Line Arguments

All scripts support `--help` for full argument docs. Key arguments:

| Argument | Default | Description |
|---|---|---|
| `--epochs` | 200 | Number of training epochs |
| `--batch-size` | 128 | Mini-batch size |
| `--lr` | 0.1 | Initial learning rate |
| `--weight-decay` | 5e-4 | L2 regularization |
| `--data-dir` | `./data` | Dataset root directory |
| `--output-dir` | `./outputs` | All outputs go here |
| `--checkpoint` | â€” | Path to model weights |
| `--resume` | â€” | Resume training from checkpoint |
| `--temperature` | 1.0 | Temperature for energy score |
| `--num-workers` | 2 | Data loading workers |
| `--seed` | 42 | Random seed |
| `--skip-train` | â€” | Skip training (main.py only) |
| `--skip-across-layers` | â€” | Skip bonus NC-across-layers |

---

## Methods Implemented

### OOD Detection

| Method | Reference | Key Idea |
|---|---|---|
| **MSP** | Hendrycks & Gimpel, ICLR 2017 | Max softmax probability |
| **Max Logit** | Hendrycks et al., ICML 2022 | Max raw logit value |
| **Energy** | Liu et al., NeurIPS 2020 | LogSumExp of logits |
| **Mahalanobis** | Lee et al., NeurIPS 2018 | Feature-space distance with shared covariance |
| **ViM** | Wang et al., CVPR 2022 | Null-space residual + virtual logit |
| **NECO** | Ammar et al., ICLR 2024 | Neural Collapse inspired cosine similarity gap |

### Neural Collapse (Papyan, Han & Donoho, PNAS 2020)

| Property | What it measures |
|---|---|
| **NC1** | Within-class variability collapse (Î£_W â†’ 0) |
| **NC2** | Class means â†’ Simplex ETF (equinorm + equiangular) |
| **NC3** | Classifier weights align with class means (self-duality) |
| **NC4** | Predictions simplify to Nearest Class Center |
| **NC5** | NCC generalizes to test data |

---

## Expected Results

With 200 epochs of training on CIFAR-100:

- **Test accuracy**: ~78â€“80%
- **OOD AUROC (SVHN)**: typically 80â€“95% depending on method
- **NC1 metric**: should be small (< 0.1), indicating within-class collapse
- **NC3 mean cosine**: should be close to 1.0 (classifier-feature alignment)
- **NC4 agreement**: should be > 95% (model â‰ˆ NCC classifier)
