# OOD Detection & Neural Collapse for CIFAR-100

Research project implementing Out-of-Distribution (OOD) detection methods and Neural Collapse analysis.

**Course**: Theory of Deep Learning (MVA + ENSTA)  
**Author**: Aziz BEN AMIRA

---

## ğŸ¯ Project Overview

This project trains a ResNet-18 classifier on CIFAR-100 and studies:
1. **6 OOD Detection Methods**: MSP, Max Logit, Energy, Mahalanobis, ViM, NECO
2. **Neural Collapse**: NC1-NC4 analysis + bonus layer-wise study
3. **Performance**: 78.65% test accuracy, 0.813-0.876 AUROC on OOD datasets

---

## ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ main.py                 # Full pipeline orchestrator
â”œâ”€â”€ config.py              # Hyperparameters & paths
â”œâ”€â”€ requirements.txt       # Dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/           # ResNet-18 for CIFAR
â”‚   â”œâ”€â”€ data/             # Data loaders (CIFAR-100, SVHN, DTD)
â”‚   â”œâ”€â”€ training/         # Training loop with checkpointing
â”‚   â”œâ”€â”€ ood/              # 6 OOD scoring methods
â”‚   â”œâ”€â”€ neural_collapse/  # NC1-NC5 metrics
â”‚   â””â”€â”€ utils/            # Feature extraction, visualization
â”‚
â”œâ”€â”€ scripts/              # Standalone CLI scripts
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate_ood.py
â”‚   â””â”€â”€ analyze_nc.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ plots/            # All visualizations (9 figures)
â”‚   â”œâ”€â”€ results/          # summary.json, training_history.json
â”‚   â””â”€â”€ checkpoints/      # Saved models (excluded from repo due to size)
â”‚
â”œâ”€â”€ analysis.md           # Personal insights & observations
â”œâ”€â”€ experiments.py        # Temperature tuning, ViM debugging
â”œâ”€â”€ STUDY_GUIDE.md        # Defense preparation notes
â””â”€â”€ TODO.md              # Work-in-progress tracking
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Training (200 epochs)

```bash
# Local execution
python main.py --epochs 200

# Or via SLURM (GPU cluster)
sbatch run_200epochs.sh
```

### Standalone Scripts

```bash
# Train only
python scripts/train.py --epochs 200 --output-dir ./outputs

# Evaluate OOD (requires trained model)
python scripts/evaluate_ood.py --checkpoint ./outputs/checkpoints/best_model.pth

# Analyze Neural Collapse
python scripts/analyze_nc.py --checkpoint ./outputs/checkpoints/best_model.pth
```

---

## ğŸ“Š Results Summary

### Training Performance
- **Test Accuracy**: 78.65% (CIFAR-100, 100 classes)
- **Best Epoch**: 161 (saved to `best_model.pth`)
- **Training Time**: ~20 minutes on NVIDIA L40S GPU

### OOD Detection (AUROC)

| Method | SVHN | DTD |
|--------|------|-----|
| Energy | **0.876** | 0.784 |
| NECO | 0.840 | **0.813** |
| Max Logit | 0.869 | 0.784 |
| MSP | 0.846 | 0.779 |
| Mahalanobis | 0.688 | 0.781 |
| ViM âš ï¸ | 0.225 | 0.451 |

### Neural Collapse Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| NC1 | 1,126,273 | Partial collapse (expected at 78% acc) |
| NC2 (angle) | -0.0101 | âœ… Perfect simplex! |
| NC3 (alignment) | 0.977 | âœ… Strong weight-mean alignment |
| NC4 (agreement) | 100% (train) | âœ… NCC = Softmax |
| NC5 (test) | 96.89% | âœ… Generalizes to test data |

---

## ğŸ”¬ Key Insights

1. **Neural Collapse is real**: Despite only 78% accuracy, NC2-NC5 show strong geometric structure
2. **Simple methods work**: Energy score (0.876 AUROC) outperforms complex ViM
3. **Dataset matters**: NECO excels on textures (DTD), Energy on street numbers (SVHN)
4. **ViM needs debugging**: Poor performance suggests hyperparameter tuning needed

---

## ğŸ“š References

- **Neural Collapse**: Papyan et al. (2020) - "Prevalence of Neural Collapse during the terminal phase of deep learning training"
- **NECO**: Inspired by Neural Collapse geometry for OOD detection
- **Energy Score**: Liu et al. (2020) - "Energy-based Out-of-distribution Detection"
- **Mahalanobis**: Lee et al. (2018) - "A Simple Unified Framework for Detecting OOD Samples"
- **ViM**: Wang et al. (2022) - "ViM: Out-Of-Distribution with Virtual-logit Matching"

---

## ğŸ“ Files to Review

- **`analysis.md`**: Personal observations and deep dive into results
- **`STUDY_GUIDE.md`**: Defense preparation with key concepts
- **`experiments.py`**: Temperature tuning and ViM debugging experiments
- **`outputs/plots/`**: 9 visualizations (training curves, OOD scores, NC analysis)

---

## âš ï¸ Known Issues

1. **ViM performance**: AUROC of 0.225 (needs hyperparameter tuning)
2. **NC1 not collapsed**: Expected at 78% accuracy; would need >95% for full collapse
3. **Large checkpoints**: Intermediate checkpoints excluded from repo (~2.6GB total)

---

## ğŸ¤ Collaboration

**Share with mate**: This repo contains full working code + results. To reproduce:
1. Download CIFAR-100 (automatic via torchvision)
2. Download OOD datasets: SVHN, DTD (handled by `get_dataloaders()`)
3. Run `main.py` or SLURM scripts

**What's included**:
- âœ… Complete working pipeline
- âœ… All results (plots, metrics, training logs)
- âœ… Personal analysis and experiments
- âœ… Study materials for defense

**What's excluded** (too large):
- âŒ Intermediate checkpoints (20 Ã— 129MB each)
- âŒ Raw datasets (downloaded on-demand)

---

## ğŸ“§ Contact

**Author**: Aziz BEN AMIRA  
**Course**: Theory of Deep Learning (MVA + ENSTA)  
**Date**: February 2026

---

## ğŸ“œ License

For educational purposes (MVA + ENSTA course project).
